{
  "hash": "1ea205ac3a7be0d6028a9ca13f0f487e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Practical 1 - Linear (Mixed) Models\"\nexecute: \n  freeze: auto\nformat: \n  html:\n    mainfont: \"12\"\n  PrettyPDF-pdf:\n    keep-tex: false\n    number-sections: true\nembed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n\nIn this practical we are going to fit linear (mixed) models in `inlabru`. \nWe are going to to:\n\n- Fit a [simple linear regression](#SLR)\n- Fit a linear regression with discrete covariates and interactions\n- Fit a linear mixed model.\n\nIn all cases we are first going to simulate our data.\nWe then fit the data and explore the results.\n\n\nStart by loading useful libraries:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load libraries\"}\nlibrary(dplyr)\nlibrary(INLA)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(inlabru)     \n# load some libraries to generate nice plots\nlibrary(scico)\n```\n:::\n\n\n\n## Simple linear regression{#SLR}\n\n\n\n## Linear Mixed Model\n\nIn this practical we will:\n\n-   Understand the basic structure of a Linear Mixed Model (LLM)\n-   Simulate data from a LMM\n-   Learn how to fit a LMM with `inlabru` and predict from the model.\n\nConsider the a simple linear regression model except with the addition that the data that comes in groups. Suppose that we want to include a random effect for each group $j$ (equivalent to adding a group random intercept). The model is then: $$\n y_{ij}  = \\beta_0 + \\beta_1 x_i + u_j + \\epsilon_{ij} ~~~  \\text{for}~i = 1,\\ldots,N~ \\text{and}~ j = 1,\\ldots,m.\n$$\n\nHere the random group effect is given by the variable $u_j \\sim \\mathcal{N}(0, \\tau^{-1}_u)$ with $\\tau_u = 1/\\sigma^2_u$ describing the variability between groups (i.e., how much the group means differ from the overall mean). Then, $\\epsilon_j \\sim \\mathcal{N}(0, \\tau^{-1}_\\epsilon)$ denotes the residuals of the model and $\\tau_\\epsilon = 1/\\sigma^2_\\epsilon$ captures how much individual observations deviate from their group mean (i.e., variability within group).\n\nThe model design matrix for the random effect has one row for each observation (this is equivalent to a random intercept model). The row of the design matrix associated with the $ij$-th observation consists of zeros except for the element associated with $u_j$, which has a one.\n\n$$\n\\pmb{\\eta} = \\pmb{A}\\pmb{u} = \\pmb{A}_1\\pmb{u}_1 + \\pmb{A}_2\\pmb{u}_2 + \\pmb{A}_3\\pmb{u}_3\n$$\n\n::: {.callout-note icon=\"false\"}\n## Supplementary material: LMM as a LGM\n\nIn matrix form, the linear mixed model for the *j*-th group can be written as:\n\n$$ \\overbrace{\\mathbf{y}_j}^{ N \\times 1} = \\overbrace{X_j}^{ N \\times 2} \\underbrace{\\beta}_{1\\times 1} + \\overbrace{Z_j}^{n_j \\times 1} \\underbrace{u_j}_{1\\times1} + \\overbrace{\\epsilon_j}^{n_j \\times 1}, $$\n\nIn a latent Gaussian model (LGM) formulation the mixed model predictor for the *i*-th observation can be written as :\n\n$$\n\\eta_i = \\beta_0 + \\beta_1 x_i + \\sum_k^K f_k(u_j)\n$$\n\nwhere $f_k(u_j) = u_j$ since thereâ€™s only one random effect per group (i.e., a random intercept for group $j$). The fixed effects $(\\beta_0,\\beta_1)$ are assigned Gaussian priors (e.g., $\\beta \\sim \\mathcal{N}(0,\\tau_\\beta^{-1})$). The random effects $\\mathbf{u} = (u_1,\\ldots,u_m)^T$ follow a Gaussian density $\\mathcal{N}(0,\\mathbf{Q}_u^{-1})$ where $\\mathbf{Q}_u = \\tau_u\\mathbf{I}_m$ is the precision matrix for the random intercepts. Then, the components for the LGM are the following:\n\n-   Latent field given by\n\n    $$\n    \\begin{bmatrix} \\beta \\\\\\mathbf{u} \n    \\end{bmatrix} \\sim \\mathcal{N}\\left(\\mathbf{0},\\begin{bmatrix}\\tau_\\beta^{-1}\\mathbf{I}_2&\\mathbf{0}\\\\\\mathbf{0} &\\tau_u^{-1}\\mathbf{I}_m\\end{bmatrix}\\right)\n    $$\n\n-   Likelihood:\n\n    $$\n    y_i \\sim \\mathcal{N}(\\eta_i,\\tau_{\\epsilon}^{-1})\n    $$\n\n-   Hyperparameters:\n\n    -   $\\tau_u\\sim\\mathrm{Gamma}(a,b)$\n    -   $\\tau_\\epsilon \\sim \\mathrm{Gamma}(c,d)$\n:::\n\n### **Simulate example data**\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Simulate data from a LMM\"}\nset.seed(12)\nbeta = c(1.5,1)\nsd_error = 1\ntau_group = 1\n\nn = 100\nn.groups = 5\nx = rnorm(n)\nv = rnorm(n.groups, sd = tau_group^{-1/2})\ny = beta[1] + beta[2] * x + rnorm(n, sd = sd_error) +\n  rep(v, each = 20)\n\ndf = data.frame(y = y, x = x, j = rep(1:5, each = 20))  \n```\n:::\n\n\nNote that `inlabru` expects an integer indexing variable to label the groups.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(df) +\n  geom_point(aes(x = x, colour = factor(j), y = y)) +\n  theme_classic() +\n  scale_colour_discrete(\"Group\")\n```\n\n::: {.cell-output-display}\n![Data for the linear mixed model example with 5 groups](LMM_ex_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n### Fitting a LMM in `inlabru`\n\n------------------------------------------------------------------------\n\n**Defining model components and observational model**\n\nIn order to specify this model we must use the `group` argument to tell `inlabru` which variable indexes the groups. The `model = \"iid\"` tells INLA that the groups are independent from one another.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define model components\ncmp =  ~ -1 + beta_0(1) + beta_1(x, model = \"linear\") +\n  u(j, model = \"iid\")\n```\n:::\n\n\nThe group variable is indexed by column `j` in the dataset. We have chosen to name this component `v()` to connect with the mathematical notation that we used above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct likelihood\nlik =  bru_obs(formula = y ~.,\n            family = \"gaussian\",\n            data = df)\n```\n:::\n\n\n**Fitting the model**\n\nThe model can be fitted exactly as in the previous examples by using the `bru` function with the components and likelihood objects.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Fit a LMM in inlabru\"}\nfit = bru(cmp, lik)\nsummary(fit)\n## inlabru version: 2.13.0.9016 \n## INLA version: 25.11.22 \n## Components: \n## Latent components:\n## beta_0: main = linear(1)\n## beta_1: main = linear(x)\n## u: main = iid(j)\n## Observation models: \n##   Family: 'gaussian'\n##     Tag: <No tag>\n##     Data class: 'data.frame'\n##     Response class: 'numeric'\n##     Predictor: y ~ .\n##     Additive/Linear: TRUE/TRUE\n##     Used components: effects[beta_0, beta_1, u], latent[] \n## Time used:\n##     Pre = 1.11, Running = 0.22, Post = 0.0408, Total = 1.37 \n## Fixed effects:\n##         mean    sd 0.025quant 0.5quant 0.975quant  mode kld\n## beta_0 2.108 0.438      1.229    2.108      2.986 2.108   0\n## beta_1 1.172 0.120      0.936    1.172      1.407 1.172   0\n## \n## Random effects:\n##   Name\t  Model\n##     u IID model\n## \n## Model hyperparameters:\n##                                          mean    sd 0.025quant 0.5quant\n## Precision for the Gaussian observations 0.995 0.144      0.738    0.986\n## Precision for u                         1.613 1.060      0.369    1.356\n##                                         0.975quant  mode\n## Precision for the Gaussian observations       1.30 0.971\n## Precision for u                               4.35 0.918\n## \n## Marginal log-Likelihood:  -179.93 \n##  is computed \n## Posterior summaries for the linear predictor and the fitted values are computed\n## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n```\n:::\n\n\n### Model predictions\n\nTo compute model predictions we can create a `data.frame` containing a range of values of covariate where we want the response to be predicted for each group. Then we simply call the predict function while specifying the model components.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"LMM fitted values\"}\n# New data\nxpred = seq(range(x)[1], range(x)[2], length.out = 100)\nj = 1:n.groups\npred_data = expand.grid(x = xpred, j = j)\npred = predict(fit, pred_data, formula = ~ beta_0 + beta_1 + u) \n\n\npred %>%\n  ggplot(aes(x=x,y=mean,color=factor(j)))+\n  geom_line()+\n  geom_ribbon(aes(x,ymin = q0.025, ymax= q0.975,fill=factor(j)), alpha = 0.5) + \n  geom_point(data=df,aes(x=x,y=y,colour=factor(j)))+\n  facet_wrap(~j)\n```\n\n::: {.cell-output-display}\n![](LMM_ex_files/figure-pdf/unnamed-chunk-9-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nSuppose that we are also interested in including random slopes into our model. Assuming intercept and slopes are independent, can your write down the linear predictor and the components of this model as a LGM?\n\n\n<div class='webex-solution'><button>Give me a hint</button>\n\n\nIn general, the mixed model predictor can decomposed as:\n\n$$ \\pmb{\\eta} = X\\beta + Z\\mathbf{u} $$\n\nWhere $X$ is a $n \\times p$ design matrix and $\\beta$ the corresponding *p*-dimensional vector of fixed effects. Then $Z$ is a $n\\times q_J$ design matrix for the $q_J$ random effects and $J$ groups; $\\mathbf{v}$ is then a $q_J \\times 1$ vector of $q$ random effects for the $J$ groups. In a latent Gaussian model (LGM) formulation this can be written as:\n\n$$ \\eta_i = \\beta_0 + \\sum\\beta_j x_{ij} + \\sum_k f(k) (u_{ij}) $$\n\n\n</div>\n\n\n\n<div class='webex-solution'><button>See Solution</button>\n\n\n-   The linear predictor is given by\n\n    $$\n    \\eta_i = \\beta_0 + \\beta_1x_i + u_{0j} + u_{1j}x_i\n    $$\n\n-   Latent field defined by:\n\n    -   $\\beta \\sim \\mathcal{N}(0,\\tau_\\beta^{-1})$\n\n    -   $\\mathbf{u}_j = \\begin{bmatrix}u_{0j} \\\\ u_{1j}\\end{bmatrix}, \\mathbf{u}_j \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{Q}_u^{-1})$ where the precision matrix is a block-diagonal matrix with entries $\\mathbf{Q}_u= \\begin{bmatrix}\\tau_{u_0} & {0} \\\\{0} & \\tau_{u_1}\\end{bmatrix}$\n\n-   The hyperparameters are then:\n\n    -   $\\tau_{u_0},\\tau_{u_1} \\text{and}~\\tau_\\epsilon$\n\nTo fit this model in `inlabru` we can simply modify the model components as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncmp =  ~ -1 + beta_0(1) + beta_1(x, model = \"linear\") +\n  u0(j, model = \"iid\") + u1(j,x, model = \"iid\")\n```\n:::\n\n\n\n</div>\n\n:::\n",
    "supporting": [
      "LMM_ex_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}